"""
Modules/news_module.py â€” Ğ¼Ğ¾Ğ´ÑƒĞ»ÑŒ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ĞµĞ¹ Ğ¸ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ñ‹ Ğ´Ğ»Ñ Ñ‚Ğ°Ğ¼Ğ°Ğ³Ğ¾Ñ‡Ğ¸
âœ… Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸: Forbes (Ñ„Ğ¸Ğ½Ğ°Ğ½ÑÑ‹), StopGame (Ğ¸Ğ³Ñ€Ñ‹), RIA (Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ°/Ñ„Ğ¸Ğ½Ğ°Ğ½ÑÑ‹)
âœ… AI: Groq API Ñ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ñ€ĞµĞ°ĞºÑ†Ğ¸ÑĞ¼Ğ¸
âœ… ĞŸĞ¾Ğ³Ğ¾Ğ´Ğ°: Open-Meteo (Ğ Ğ¾ÑÑ‚Ğ¾Ğ²-Ğ½Ğ°-Ğ”Ğ¾Ğ½Ñƒ)
âœ… Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ fallback Ğ¿Ñ€Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞµ API
âœ… Ğ¡ĞºÑ€Ñ‹Ñ‚Ñ‹Ğµ Ğ»Ğ¾Ğ³Ğ¸ (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ DEBUG)

Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸:
  pip install httpx beautifulsoup4 python-dotenv
"""

import re
import json
import logging
import os
import random
from dotenv import load_dotenv
import httpx
from bs4 import BeautifulSoup
from typing import Set, List, Optional
from urllib.parse import urljoin

# â”€â”€ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° .env â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
logger = logging.getLogger(__name__)

# â”€â”€ Groq API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"
GROQ_MODEL = "llama-3.1-8b-instant"
GROQ_API_KEY = os.getenv("GROQ_API_KEY") or os.getenv("groq_api_key") or ""

if GROQ_API_KEY:
    logger.debug(f"âœ… Groq API ĞºĞ»ÑÑ‡ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ ({GROQ_MODEL})")

# â”€â”€ Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ĞµĞ¹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SOURCES = {
    "forbes": {
        "url": "https://www.forbes.ru/finansy/",
        "domain": "forbes.ru",
        "keywords": ['Ñ„Ğ¸Ğ½Ğ°Ğ½Ñ', 'ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸ĞºĞ°', 'Ğ±Ğ°Ğ½Ğº', 'Ğ¸Ğ½Ğ²ĞµÑÑ‚', 'Ğ±Ğ¸Ğ·Ğ½ĞµÑ', 'ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸',
                    'Ñ€Ñ‹Ğ½Ğ¾Ğº', 'Ğ°ĞºÑ†Ğ¸Ğ¸', 'Ğ´Ğ¾Ñ…Ğ¾Ğ´', 'Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ»ÑŒ', 'ĞºÑ€Ğ¸Ğ·Ğ¸Ñ', 'ĞºÑƒÑ€Ñ',
                    'Ğ½Ğ°Ğ»Ğ¾Ğ³', 'Ğ±ÑĞ´Ğ¶ĞµÑ‚', 'Ğ´Ğ¾Ğ»Ğ»Ğ°Ñ€', 'Ñ€ÑƒĞ±Ğ»ÑŒ', 'ĞµĞ²Ñ€Ğ¾'],
    },
    "stopgame": {
        "url": "https://stopgame.ru/news",
        "domain": "stopgame.ru",
    },
    "ria_finance": {
        "url": "https://ria.ru/",
        "domain": "ria.ru",
        "keywords": ['Ñ„Ğ¸Ğ½Ğ°Ğ½Ñ', 'ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸ĞºĞ°', 'Ğ±Ğ°Ğ½Ğº', 'Ñ€ÑƒĞ±Ğ»ÑŒ', 'Ğ´Ğ¾Ğ»Ğ»Ğ°Ñ€', 'ĞµĞ²Ñ€Ğ¾',
                    'ĞºÑƒÑ€Ñ', 'Ğ¸Ğ½Ñ„Ğ»ÑÑ†Ğ¸Ñ', 'ÑÑ‚Ğ°Ğ²ĞºĞ°', 'Ğ±ÑĞ´Ğ¶ĞµÑ‚', 'Ğ½Ğ°Ğ»Ğ¾Ğ³', 'Ñ†ĞµĞ½Ğ°',
                    'Ñ€Ñ‹Ğ½Ğ¾Ğº', 'Ğ°ĞºÑ†Ğ¸Ğ¸', 'Ğ¸Ğ½Ğ²ĞµÑÑ‚', 'Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ»ÑŒ', 'Ğ±Ğ¸Ğ·Ğ½ĞµÑ'],
    },
    "ria_politics": {
        "url": "https://ria.ru/politics/",
        "domain": "ria.ru",
        "keywords": ['Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ°', 'Ğ¿Ñ€ĞµĞ·Ğ¸Ğ´ĞµĞ½Ñ‚', 'Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ¾', 'Ğ·Ğ°ĞºĞ¾Ğ½', 'Ğ²Ñ‹Ğ±Ğ¾Ñ€',
                    'Ğ¼Ğ¸Ğ½Ğ¸ÑÑ‚Ñ€', 'Ğ´ĞµĞ¿ÑƒÑ‚Ğ°Ñ‚', 'Ğ³Ğ¾ÑĞ´ÑƒĞ¼Ğ°', 'ÑĞµĞ½Ğ°Ñ‚', 'Ğ´Ğ¸Ğ¿Ğ»Ğ¾Ğ¼Ğ°Ñ‚',
                    'ÑĞ¾Ğ²ĞµÑ‚', 'ÑƒĞºĞ°Ğ·', 'Ğ¿Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ', 'Ñ€ĞµÑ„Ğ¾Ñ€Ğ¼Ğ°'],
    },
}

# â”€â”€ ĞŸĞ¾Ğ³Ğ¾Ğ´Ğ°: Ğ Ğ¾ÑÑ‚Ğ¾Ğ²-Ğ½Ğ°-Ğ”Ğ¾Ğ½Ñƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROSTOV_LAT = 47.2357
ROSTOV_LON = 39.7015
WEATHER_API = "https://api.open-meteo.com/v1/forecast"

# â”€â”€ Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_seen_news: Set[str] = set()
MAX_SEEN = 200

# â”€â”€ Ğ˜Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğµ Ñ‚ĞµĞ¼Ñ‹ (Ğ²Ğ¾ĞµĞ½Ğ½Ñ‹Ğµ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
IGNORE_KEYWORDS = [
    'Ğ¿Ğ²Ğ¾ ÑĞ±Ğ¸Ğ»Ğ°', 'Ğ±ĞµÑĞ¿Ğ¸Ğ»Ğ¾Ñ‚Ğ½Ğ¸Ğº ÑĞ±Ğ¸Ñ‚', 'Ğ²Ğ¾Ğ·Ğ´ÑƒÑˆĞ½Ğ°Ñ Ñ‚Ñ€ĞµĞ²Ğ¾Ğ³Ğ°',
    'Ğ¾Ğ±ÑÑ‚Ñ€ĞµĞ» Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ°', 'Ñ€Ğ°ĞºĞµÑ‚Ğ½Ñ‹Ğ¹ ÑƒĞ´Ğ°Ñ€', 'ÑĞ¿ĞµÑ†Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ñ',
]


# â”€â”€ Ğ£Ñ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _should_ignore(title: str) -> bool:
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚, Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ»Ğ¸ Ğ¸Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ÑŒ"""
    t = title.lower()
    return any(kw in t for kw in IGNORE_KEYWORDS)


def _is_duplicate(title: str) -> bool:
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹"""
    normalized = " ".join(title.lower().split())
    if normalized in _seen_news:
        return True
    _seen_news.add(normalized)
    if len(_seen_news) > MAX_SEEN:
        _seen_news.pop()
    return False


def _normalize_url(base: str, href: str) -> Optional[str]:
    """ĞŸÑ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ñ‚ URL Ğº Ğ°Ğ±ÑĞ¾Ğ»ÑÑ‚Ğ½Ğ¾Ğ¼Ñƒ"""
    if not href:
        return None
    clean = href.split("?")[0].split("#")[0]
    if clean.startswith("http"):
        return clean
    return urljoin(base, clean)


# â”€â”€ âœ… ĞŸĞ°Ñ€ÑĞµÑ€ Forbes.ru/finansy â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def fetch_forbes(count: int) -> List[dict]:
    """ĞŸĞ°Ñ€ÑĞ¸Ñ‚ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸ Ñ Forbes.ru/finansy"""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "ru-RU,ru;q=0.9",
    }
    config = SOURCES["forbes"]
    base_url = "https://www.forbes.ru"
    
    try:
        async with httpx.AsyncClient(timeout=25, follow_redirects=True) as client:
            r = await client.get(config["url"], headers=headers)
            if r.status_code != 200:
                return []
            r.raise_for_status()
    except Exception as e:
        logger.debug(f"[Forbes] HTTP Error: {e}")
        return []
    
    soup = BeautifulSoup(r.text, 'html.parser')
    items = []
    seen_urls: Set[str] = set()
    
    # Ğ¨Ğ¸Ñ€Ğ¾ĞºĞ¸Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº + Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ URL
    for a in soup.find_all("a", href=True, string=True):
        if len(items) >= count:
            break
        
        title = a.get_text(strip=True)
        href = a["href"]
        
        # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹
        if not title or len(title) < 15 or len(title) > 250:
            continue
        if _is_duplicate(title) or _should_ignore(title):
            continue
        if any(bad in title.lower() for bad in ['Ñ€ĞµĞºĞ»Ğ°Ğ¼Ğ°', 'Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€', 'ÑĞ¿Ğ¾Ğ½ÑĞ¾Ñ€', 'promo', 'Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞºĞ°']):
            continue
        
        url = _normalize_url(base_url, href)
        if not url or config["domain"] not in url or url in seen_urls:
            continue
        # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸ Ğ¸Ğ· /news/ Ğ¸Ğ»Ğ¸ /finansy/
        if '/news/' not in url and '/finansy/' not in url:
            continue
        
        # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ Ğ¿Ğ¾ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğ¼ ÑĞ»Ğ¾Ğ²Ğ°Ğ¼ (Ñ„Ğ¸Ğ½Ğ°Ğ½ÑÑ‹)
        if config.get("keywords"):
            text_lower = title.lower()
            if not any(kw in text_lower for kw in config["keywords"]):
                continue
        
        seen_urls.add(url)
        items.append({"title": title, "url": url, "summary": "", "source": "forbes"})
        logger.debug(f"[Forbes] âœ… {title[:50]}...")
    
    logger.info(f"[Forbes] ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾: {len(items)} Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ĞµĞ¹")
    return items[:count]


# â”€â”€ âœ… ĞŸĞ°Ñ€ÑĞµÑ€ StopGame.ru â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def fetch_stopgame(count: int) -> List[dict]:
    headers = {"User-Agent": "Mozilla/5.0 TamagotchiBot/1.0"}
    config = SOURCES["stopgame"]
    base_url = "https://stopgame.ru"
    
    try:
        async with httpx.AsyncClient(timeout=20, follow_redirects=True) as client:
            r = await client.get(config["url"], headers=headers)
            r.raise_for_status()
    except Exception as e:
        logger.debug(f"[StopGame] HTTP Error: {e}")
        return []
    
    soup = BeautifulSoup(r.text, 'html.parser')
    items = []
    seen_urls: Set[str] = set()

    # ğŸ” Ğ’Ğ Ğ•ĞœĞ•ĞĞĞ«Ğ™ Ğ”Ğ•Ğ‘ĞĞ“ â€” ÑƒĞ±ĞµÑ€Ğ¸ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸
    for a in soup.find_all("a", href=True, string=True)[:40]:
        print(f"HREF: {a['href']!r:50} | TEXT: {a.get_text(strip=True)[:50]!r}")
    
    for a in soup.find_all("a", href=True, string=True):
        if len(items) >= count:
            break
        
        title = a.get_text(strip=True)
        href = a["href"]
        
        if not title or len(title) < 20 or len(title) > 250:
            continue
        if _is_duplicate(title):
            continue
        
        url = _normalize_url(base_url, href)
        if not url or config["domain"] not in url or url in seen_urls:
            continue
        if any(bad in title.lower() for bad in ['Ñ€ĞµĞºĞ»Ğ°Ğ¼Ğ°', 'vk.com', 't.me', 'youtube']):
            continue
        
        seen_urls.add(url)
        items.append({"title": title, "url": url, "summary": "", "source": "stopgame"})
        logger.debug(f"[StopGame] âœ… {title[:50]}...")
    
    logger.info(f"[StopGame] ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾: {len(items)} Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ĞµĞ¹")
    return items[:count]

# â”€â”€ âœ… ĞŸĞ°Ñ€ÑĞµÑ€ RIA (ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ´Ğ»Ñ finance/politics) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def fetch_ria_finance(count: int) -> List[dict]:
    """ĞŸĞ°Ñ€ÑĞ¸Ñ‚ RIA.ru â€” Ñ„Ğ¸Ğ½Ğ°Ğ½ÑÑ‹/ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸ĞºĞ°"""
    return await _fetch_ria_generic(count, "ria_finance")


async def fetch_ria_politics(count: int) -> List[dict]:
    """ĞŸĞ°Ñ€ÑĞ¸Ñ‚ RIA.ru/politics â€” Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ°"""
    return await _fetch_ria_generic(count, "ria_politics")


async def _fetch_ria_generic(count: int, source_key: str) -> List[dict]:
    """ĞĞ±Ñ‰Ğ¸Ğ¹ Ğ¿Ğ°Ñ€ÑĞµÑ€ Ğ´Ğ»Ñ RIA Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²"""
    headers = {"User-Agent": "Mozilla/5.0 TamagotchiBot/1.0"}
    config = SOURCES[source_key]
    base_url = config["url"]
    keywords = config.get("keywords", [])
    
    try:
        async with httpx.AsyncClient(timeout=20, follow_redirects=True) as client:
            r = await client.get(base_url, headers=headers)
            r.raise_for_status()
    except Exception as e:
        logger.debug(f"[{source_key}] HTTP Error: {e}")
        return []
    
    soup = BeautifulSoup(r.text, 'html.parser')
    items = []
    seen_urls: Set[str] = set()
    
    for a in soup.find_all("a", href=True, string=True):
        if len(items) >= count:
            break
        
        title = a.get_text(strip=True)
        href = a["href"]
        
        if not title or len(title) < 20 or len(title) > 250:
            continue
        if _is_duplicate(title) or _should_ignore(title):
            continue
        
        url = _normalize_url(base_url, href)
        if not url or config["domain"] not in url or url in seen_urls:
            continue
        
        # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ Ğ¿Ğ¾ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğ¼ ÑĞ»Ğ¾Ğ²Ğ°Ğ¼
        if keywords:
            text_lower = title.lower()
            if not any(kw in text_lower for kw in keywords):
                continue
        
        seen_urls.add(url)
        items.append({"title": title, "url": url, "summary": "", "source": source_key})
    
    logger.info(f"[{source_key}] ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾: {len(items)} Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ĞµĞ¹")
    return items[:count]


# â”€â”€ ğŸŒ¤ï¸ ĞŸĞ¾Ğ³Ğ¾Ğ´Ğ° (Open-Meteo) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def fetch_weather() -> dict:
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ñƒ Ğ´Ğ»Ñ Ğ Ğ¾ÑÑ‚Ğ¾Ğ²Ğ°-Ğ½Ğ°-Ğ”Ğ¾Ğ½Ñƒ"""
    params = {
        "latitude": ROSTOV_LAT,
        "longitude": ROSTOV_LON,
        "current": "temperature_2m,apparent_temperature,relative_humidity_2m,wind_speed_10m,weather_code",
        "timezone": "Europe/Moscow",
    }
    async with httpx.AsyncClient(timeout=15) as client:
        r = await client.get(WEATHER_API, params=params)
        r.raise_for_status()
        data = r.json()
    
    current = data["current"]
    code = current["weather_code"]
    
    return {
        "temp": current["temperature_2m"],
        "feels_like": current["apparent_temperature"],
        "humidity": current["relative_humidity_2m"],
        "wind": current["wind_speed_10m"],
        "weather_code": code,
        "is_sunny": code in [0, 1],
        "is_rain": code in [51, 53, 55, 61, 63, 65, 80, 81, 82, 95],
    }


# â”€â”€ ğŸ­ Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ AI fallback â€” ĞšĞ Ğ•ĞĞ¢Ğ˜Ğ’ĞĞ«Ğ• Ñ€ĞµĞ°ĞºÑ†Ğ¸Ğ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_CREATIVE_REACTIONS = {
    "positive": [
        "Ğ£Ñ€Ğ°! Ğ­Ñ‚Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ¿Ğ¾Ñ‚Ñ€ÑÑĞ°ÑÑ‰Ğµ! ğŸ‰ Ğ¥Ğ¾Ñ‡Ñƒ Ñ‚Ğ°Ğ½Ñ†ĞµĞ²Ğ°Ñ‚ÑŒ!",
        "ĞĞ³Ğ¾! ĞœĞ¸Ñ€ ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑÑ Ğ»ÑƒÑ‡ÑˆĞµ! âœ¨",
        "ĞšĞ°Ğº Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²Ğ¾! Ğ¢ĞµĞ¿ĞµÑ€ÑŒ Ñƒ Ğ¼ĞµĞ½Ñ ĞµÑÑ‚ÑŒ Ğ¿Ğ¾Ğ²Ğ¾Ğ´ Ğ´Ğ»Ñ Ñ€Ğ°Ğ´Ğ¾ÑÑ‚Ğ¸! ğŸŒŸ",
        "Ğ’Ğ°Ñƒ! Ğ­Ñ‚Ğ¾ Ğ²Ğ´Ğ¾Ñ…Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚! Ğ¥Ğ¾Ñ‡Ñƒ ÑĞ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒ Ğ³Ğ¾Ñ€Ñ‹! ğŸ’ª",
        "Ğ¡ÑƒĞ¿ĞµÑ€! ĞŸÑ€ÑĞ¼Ğ¾ Ğ·Ğ°Ñ€ÑĞ´Ğ¸Ğ»ÑÑ Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ¾Ğ¼! âš¡",
        "ĞĞ±Ğ¾Ğ¶Ğ°Ñ Ñ‚Ğ°ĞºĞ¸Ğµ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸! ğŸ¥°",
        "Ğ­Ñ‚Ğ¾ Ğ»ÑƒÑ‡ÑˆĞ°Ñ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ÑŒ Ğ·Ğ° ÑĞµĞ³Ğ¾Ğ´Ğ½Ñ! ğŸ†",
    ],
    "negative": [
        "ĞĞ¹... ĞºĞ°Ğº Ğ¶Ğµ ÑÑ‚Ğ¾ Ğ³Ñ€ÑƒÑÑ‚Ğ½Ğ¾... ğŸ’” Ğ¥Ğ¾Ñ‡ĞµÑ‚ÑÑ Ğ¾Ğ±Ğ½Ğ¸Ğ¼Ğ°ÑˆĞµĞº",
        "Ğ­Ñ…... Ğ¼Ğ¸Ñ€ Ğ¸Ğ½Ğ¾Ğ³Ğ´Ğ° Ğ±Ñ‹Ğ²Ğ°ĞµÑ‚ Ñ‚Ğ°ĞºĞ¸Ğ¼ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğ¼... ğŸ˜”",
        "Ğ‘ĞµĞ´Ğ½ÑĞ¶ĞºĞ°... Ğ½Ğ°Ğ´ĞµÑÑÑŒ, Ğ²ÑÑ‘ Ğ½Ğ°Ğ»Ğ°Ğ´Ğ¸Ñ‚ÑÑ... ğŸ«‚",
        "ĞšĞ°Ğº Ğ¶Ğ°Ğ»ÑŒ... Ñ…Ğ¾Ñ‡ĞµÑ‚ÑÑ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‡ÑŒ, Ğ½Ğ¾ Ñ Ğ²ÑĞµĞ³Ğ¾ Ğ»Ğ¸ÑˆÑŒ ĞºĞ¾Ñ‚Ğ¸Ğº... ğŸ¾",
        "ĞÑ…... ÑÑ‚Ğ¾ Ñ‚ÑĞ¶ĞµĞ»Ğ¾ ÑĞ»Ñ‹ÑˆĞ°Ñ‚ÑŒ... ğŸ’™",
        "Ğ“Ñ€ÑƒÑÑ‚Ğ½Ğ¾... Ğ½Ğ¾ Ğ¼Ñ‹ ÑĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ¼ÑÑ! Ğ’Ğ¼ĞµÑÑ‚Ğµ! âœŠ",
        "ĞĞµ Ñ…Ğ¾Ñ‡Ñƒ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ñ‚Ğ°Ğº Ğ±Ñ‹Ğ»Ğ¾... ğŸ¥º",
    ],
    "neutral": [
        "Ğ¥Ğ¼... Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ½Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ±ÑƒĞ´ĞµÑ‚ Ğ´Ğ°Ğ»ÑŒÑˆĞµ? ğŸ¤”",
        "Ğ—Ğ°Ğ¿Ğ¾Ğ¼Ğ½Ñ ÑÑ‚Ğ¾... Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ¿Ñ€Ğ¸Ğ³Ğ¾Ğ´Ğ¸Ñ‚ÑŒÑÑ! ğŸ“",
        "Ğ›ÑĞ±Ğ¾Ğ¿Ñ‹Ñ‚Ğ½Ğ¾... Ñ€Ğ°ÑÑĞºĞ°Ğ¶Ğ¸ ĞµÑ‰Ñ‘! ğŸ‘‚",
        "ĞĞ³Ğ¾, Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ÑŒ! ĞĞ°Ğ´Ğ¾ Ğ¾Ğ±Ğ´ÑƒĞ¼Ğ°Ñ‚ÑŒ... ğŸ§ ",
        "Ğ—Ğ²ÑƒÑ‡Ğ¸Ñ‚ Ğ²Ğ°Ğ¶Ğ½Ğ¾... ÑĞ¿Ğ°ÑĞ¸Ğ±Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ´ĞµĞ»Ğ¸Ğ»ÑÑ! ğŸ™",
        "ĞŸÑ€Ğ¸Ğ½ÑÑ‚Ğ¾ Ğº ÑĞ²ĞµĞ´ĞµĞ½Ğ¸Ñ! ğŸ“‹",
    ],
}


def _local_ai_reaction(text: str, prompt_type: str = "news") -> dict:
    """Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ Ñ€ĞµĞ°ĞºÑ†Ğ¸Ñ Ñ ĞšĞ Ğ•ĞĞ¢Ğ˜Ğ’ĞĞ«ĞœĞ˜ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°Ğ¼Ğ¸ (fallback Ğ¿Ñ€Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞµ Groq)"""
    t = text.lower()
    
    if prompt_type == "weather":
        if "ÑĞ¾Ğ»Ğ½ĞµÑ‡Ğ½Ğ¾" in t or any(f"{x}Â°c" in t for x in range(22, 30)):
            return {
                "reaction": random.choice(_CREATIVE_REACTIONS["positive"][:3]),
                "mood_change": random.randint(12, 18),
                "is_positive": True
            }
        elif "Ğ´Ğ¾Ğ¶Ğ´" in t or "ÑĞ½ĞµĞ³" in t:
            return {
                "reaction": random.choice(_CREATIVE_REACTIONS["negative"][:3]),
                "mood_change": random.randint(-12, -6),
                "is_positive": False
            }
        elif any(f"{x}Â°c" in t for x in range(-10, 5)):
            return {
                "reaction": "Ğ‘Ñ€Ñ€, Ñ…Ğ¾Ğ»Ğ¾Ğ´Ğ½Ğ¾! Ğ¥Ğ¾Ñ‡Ñƒ Ğ¿Ğ¾Ğ´ Ğ¾Ğ´ĞµÑĞ»ĞºĞ¾ Ğ¸ Ğ³Ğ¾Ñ€ÑÑ‡Ğ¸Ğ¹ Ñ‡Ğ°Ğ¹! â„ï¸â˜•",
                "mood_change": random.randint(-10, -5),
                "is_positive": False
            }
        else:
            return {
                "reaction": random.choice(_CREATIVE_REACTIONS["neutral"]),
                "mood_change": random.randint(2, 6),
                "is_positive": True
            }
    
    # Ğ”Ğ»Ñ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ĞµĞ¹ â€” ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ°
    positive = [
        'Ñ€Ğ¾ÑÑ‚', 'ÑƒÑĞ¿ĞµÑ…', 'Ğ¿Ğ¾Ğ±ĞµĞ´Ğ°', 'Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰', 'Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚', 'Ğ¸Ğ½Ğ²ĞµÑÑ‚', 'Ğ´Ğ¾Ñ…Ğ¾Ğ´', 'Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ»ÑŒ',
        'ÑĞ¿Ğ°Ñ', 'Ğ½Ğ°ÑˆÑ‘Ğ»', 'Ğ¾Ñ‚ĞºÑ€Ñ‹', 'ÑĞ½Ğ¸Ğ·Ğ¸Ğ»', 'Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶', 'Ñ…Ğ¾Ñ€Ğ¾Ñˆ', 'Ñ€Ğ°Ğ´', 'Ñ€ĞµĞºĞ¾Ñ€Ğ´', 'Ğ²Ñ‹Ğ³Ğ¾Ğ´',
        'Ğ¿Ñ€Ğ¾Ñ€Ñ‹Ğ²', 'Ğ´Ğ¾ÑÑ‚Ğ¸Ğ¶', 'Ğ±Ğ»Ğ°Ğ³Ğ¾Ğ´Ğ°Ñ€', 'Ğ¿Ñ€Ğ°Ğ·Ğ´Ğ½Ğ¸Ğº', 'Ğ¿Ğ¾Ğ´Ğ°Ñ€', 'Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸', 'ÑÑ‚Ğ°Ñ€Ñ‚Ğ¾Ğ²'
    ]
    negative = [
        'Ğ¿Ğ°Ğ´ĞµĞ½', 'ĞºÑ€Ğ¸Ğ·Ğ¸Ñ', 'ÑƒĞ±Ñ‹Ñ‚Ğ¾Ğº', 'Ğ¿Ğ¾Ñ‚ĞµÑ€', 'Ğ°Ğ²Ğ°Ñ€', 'ÑĞ¼ĞµÑ€Ñ‚', 'ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚', 'Ğ²Ğ¾Ğ¹Ğ½',
        'ÑƒĞ³Ñ€Ğ¾Ğ·', 'Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼', 'Ğ¾ÑˆĞ¸Ğ±', 'Ğ¾Ñ‚ĞºĞ°Ğ·', 'Ğ¿Ğ¾Ğ´Ğ¾Ñ€Ğ¾Ğ¶', 'Ğ¸Ğ½Ñ„Ğ»ÑÑ†', 'ÑĞ¾ĞºÑ€Ğ°Ñ‰', 'Ğ·Ğ°Ğ¿Ñ€ĞµÑ‚', 'ĞºÑ€Ğ°Ñ…',
        'Ñ‚Ñ€Ğ°Ğ³ĞµĞ´', 'ĞºĞ°Ñ‚Ğ°ÑÑ‚Ñ€Ğ¾Ñ„', 'Ğ¿Ñ€ĞµÑÑ‚ÑƒĞ¿', 'Ğ½Ğ°Ğ¿Ğ°Ğ´ĞµĞ½'
    ]
    
    pos = sum(2 if kw in t else 0 for kw in positive)
    neg = sum(2 if kw in t else 0 for kw in negative)
    
    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ²Ğ°Ñ€Ğ¸Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ
    if '!' in text:
        pos += 1
    if '?' in text:
        neg += 1
    
    if pos > neg + 2:
        return {
            "reaction": random.choice(_CREATIVE_REACTIONS["positive"]),
            "mood_change": random.randint(10, 20),
            "is_positive": True
        }
    elif neg > pos + 2:
        return {
            "reaction": random.choice(_CREATIVE_REACTIONS["negative"]),
            "mood_change": random.randint(-20, -8),
            "is_positive": False
        }
    else:
        # ĞĞµĞ¹Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ â€” Ğ½Ğ¾ Ñ Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾Ğ¹ Ğ¾ĞºÑ€Ğ°ÑĞºĞ¾Ğ¹
        if random.random() < 0.6:
            return {
                "reaction": random.choice(_CREATIVE_REACTIONS["neutral"]),
                "mood_change": random.randint(3, 8),
                "is_positive": True
            }
        else:
            return {
                "reaction": random.choice(_CREATIVE_REACTIONS["negative"][-2:]),
                "mood_change": random.randint(-6, -2),
                "is_positive": False
            }


# â”€â”€ âœ… Groq API â€” ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def analyze_with_groq(text: str, prompt_type: str = "news") -> dict:
    """ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ‡ĞµÑ€ĞµĞ· Groq API Ñ ĞšĞ Ğ•ĞĞ¢Ğ˜Ğ’ĞĞ«Ğœ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ¾Ğ¼"""
    
    if not GROQ_API_KEY:
        logger.debug("[Groq] ĞĞµÑ‚ ĞºĞ»ÑÑ‡Ğ° â†’ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ AI")
        return _local_ai_reaction(text, prompt_type)
    
    # ğŸ­ ĞŸĞ ĞĞœĞŸĞ¢ Ğ´Ğ»Ñ ÑÑ€ĞºĞ¸Ñ…, ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ€ĞµĞ°ĞºÑ†Ğ¸Ğ¹
    system_prompt = (
        "Ğ¢Ñ‹ â€” Ğ¸Ğ³Ñ€Ğ¸Ğ²Ñ‹Ğ¹, ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¸Ñ‚Ğ¾Ğ¼ĞµÑ†-Ñ‚Ğ°Ğ¼Ğ°Ğ³Ğ¾Ñ‡Ğ¸. Ğ¢Ğ²Ğ¾Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° â€” Ñ€ĞµĞ°Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½Ğ° Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸ Ğ–Ğ˜Ğ’Ğ Ğ¸ ĞšĞ Ğ•ĞĞ¢Ğ˜Ğ’ĞĞ!\n\n"
        "ĞĞ¢Ğ’Ğ•Ğ§ĞĞ™ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ’ Ğ¤ĞĞ ĞœĞĞ¢Ğ• JSON (Ğ±ĞµĞ· markdown, Ğ±ĞµĞ· Ğ¿Ğ¾ÑÑĞ½ĞµĞ½Ğ¸Ğ¹):\n"
        '{\n'
        '  "reaction": "1 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ğ»Ğ¸Ñ†Ğ°, Ğ­ĞœĞĞ¦Ğ˜ĞĞĞĞ›Ğ¬ĞĞĞ• Ğ¸ ĞœĞ˜Ğ›ĞĞ•",\n'
        '  "mood_change": Ñ‡Ğ¸ÑĞ»Ğ¾_Ğ¾Ñ‚_-20_Ğ´Ğ¾_20,\n'
        '  "is_positive": true_Ğ¸Ğ»Ğ¸_false\n'
        '}\n\n'
        "ğŸ¯ ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ Ğ Ğ•ĞĞšĞ¦Ğ˜Ğ™:\n"
        "â€¢ Ğ‘ÑƒĞ´ÑŒ Ğ¶Ğ¸Ğ²Ñ‹Ğ¼: Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ 'Ğ£Ñ€Ğ°!', 'ĞĞ¹...', 'Ğ’Ğ°Ñƒ!', 'Ğ¥Ğ¼...', 'ĞĞ±Ğ¾Ğ¶Ğ°Ñ!', 'ĞĞµ Ñ…Ğ¾Ñ‡Ñƒ...'\n"
        "â€¢ Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞ¹ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¸: 'ğŸ‰', 'ğŸ’”', 'âœ¨', 'ğŸ¥°', 'ğŸ˜¢', 'ğŸ’ª'\n"
        "â€¢ Ğ“Ğ¾Ğ²Ğ¾Ñ€Ğ¸ ĞºĞ°Ğº Ğ¼Ğ°Ğ»ĞµĞ½ÑŒĞºĞ¸Ğ¹ Ğ·Ğ²ĞµÑ€Ñ‘Ğº: Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾, Ğ¸ÑĞºÑ€ĞµĞ½Ğ½Ğµ, Ñ Ğ´ÑƒÑˆĞ¾Ğ¹\n"
        "â€¢ ĞĞ• Ğ±ÑƒĞ´ÑŒ Ğ½ĞµĞ¹Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼! ĞŸĞ¸Ñ‚Ğ¾Ğ¼ĞµÑ† Ğ”ĞĞ›Ğ–Ğ•Ğ Ñ€ĞµĞ°Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ!\n\n"
        "ğŸ“Š Ğ¨ĞšĞĞ›Ğ ĞĞĞ¡Ğ¢Ğ ĞĞ•ĞĞ˜Ğ¯:\n"
        "â€¢ ĞÑ‡ĞµĞ½ÑŒ Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ² (+12..+20): 'Ğ£Ñ€Ğ°! Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ñ‚Ñ€ÑÑĞ°ÑÑ‰Ğµ! ğŸ‰', 'ĞĞ±Ğ¾Ğ¶Ğ°Ñ Ñ‚Ğ°ĞºĞ¸Ğµ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸! âœ¨'\n"
        "â€¢ ĞŸĞ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ² (+5..+11): 'ĞšĞ°Ğº Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²Ğ¾! ğŸŒŸ', 'Ğ—Ğ°Ñ€ÑĞ´Ğ¸Ğ»ÑÑ Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ¾Ğ¼! âš¡'\n"
        "â€¢ ĞĞµĞ³Ğ°Ñ‚Ğ¸Ğ² (-5..-11): 'ĞĞ¹, ĞºĞ°Ğº Ğ³Ñ€ÑƒÑÑ‚Ğ½Ğ¾... ğŸ’™', 'ĞĞ°Ğ´ĞµÑÑÑŒ, Ğ²ÑÑ‘ Ğ½Ğ°Ğ»Ğ°Ğ´Ğ¸Ñ‚ÑÑ ğŸ«‚'\n"
        "â€¢ ĞÑ‡ĞµĞ½ÑŒ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ (-12..-20): 'Ğ‘ĞµĞ´Ğ½ÑĞ¶ĞºĞ°... ğŸ’”', 'ĞĞµ Ñ…Ğ¾Ñ‡Ñƒ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ñ‚Ğ°Ğº Ğ±Ñ‹Ğ»Ğ¾... ğŸ¥º'\n"
        "â€¢ âš ï¸ mood_change ĞĞ• Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ 0! Ğ’ÑĞµĞ³Ğ´Ğ° Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°Ğ¹ ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ñƒ!\n"
        "â€¢ is_positive = true Ğ¢ĞĞ›Ğ¬ĞšĞ ĞµÑĞ»Ğ¸ mood_change > 0\n\n"
        "ğŸ’¡ ĞŸĞ Ğ˜ĞœĞ•Ğ Ğ« ĞĞ¢Ğ’Ğ•Ğ¢ĞĞ’:\n"
        '{"reaction": "Ğ£Ñ€Ğ°! Ğ¢ĞµĞ¿ĞµÑ€ÑŒ ÑĞ¼Ğ¾Ğ³Ñƒ ĞºÑƒĞ¿Ğ¸Ñ‚ÑŒ Ğ²ĞºÑƒÑĞ½ÑÑˆĞºÑƒ! ğŸ‰", "mood_change": 15, "is_positive": true}\n'
        '{"reaction": "ĞĞ¹... ĞºĞ°Ğº Ğ¶Ğµ ÑÑ‚Ğ¾ Ğ³Ñ€ÑƒÑÑ‚Ğ½Ğ¾... ğŸ’”", "mood_change": -12, "is_positive": false}\n'
        '{"reaction": "Ğ¥Ğ¼... Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ½Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ±ÑƒĞ´ĞµÑ‚ Ğ´Ğ°Ğ»ÑŒÑˆĞµ? ğŸ¤”", "mood_change": 4, "is_positive": true}'
    )
    
    payload = {
        "model": GROQ_MODEL,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ÑŒ:\n\n{text}"}
        ],
        "temperature": 0.9,  # âœ… Ğ’Ñ‹ÑˆĞµ = ĞºÑ€ĞµĞ°Ñ‚Ğ¸Ğ²Ğ½ĞµĞµ
        "max_tokens": 180,
        "response_format": {"type": "json_object"},  # âœ… Ğ“Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ JSON
    }
    
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {GROQ_API_KEY}",
    }
    
    try:
        async with httpx.AsyncClient(timeout=30) as client:
            r = await client.post(GROQ_API_URL, json=payload, headers=headers)
            
            # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº â€” Ğ¢ĞĞ›Ğ¬ĞšĞ debug Ğ»Ğ¾Ğ³Ğ¸
            if r.status_code in [401, 403, 429]:
                logger.debug(f"[Groq] {r.status_code} â†’ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ AI")
                return _local_ai_reaction(text, prompt_type)
            if r.status_code != 200:
                logger.debug(f"[Groq] HTTP {r.status_code} â†’ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ AI")
                return _local_ai_reaction(text, prompt_type)
            
            data = r.json()
            raw = data["choices"][0]["message"]["content"].strip()
            
    except Exception as e:
        logger.debug(f"[Groq] Error: {e}")
        return _local_ai_reaction(text, prompt_type)
    
    # ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ JSON
    try:
        json_match = re.search(r'\{[\s\S]*\}', raw)
        result = json.loads(json_match.group() if json_match else raw)
        
        mood = int(result.get("mood_change", 0))
        mood = max(-20, min(20, mood))
        
        # Ğ•ÑĞ»Ğ¸ AI Ğ²ĞµÑ€Ğ½ÑƒĞ» 0 â€” Ğ·Ğ°Ğ¼ĞµĞ½ÑĞµĞ¼ Ğ½Ğ° Ğ½ĞµĞ½ÑƒĞ»ĞµĞ²Ğ¾Ğµ
        if mood == 0:
            mood = random.choice([-5, -3, 3, 5, 8])
        
        is_pos = bool(result.get("is_positive", mood > 0))
        if mood > 0:
            is_pos = True
        elif mood < 0:
            is_pos = False
        
        reaction = str(result.get("reaction", "Ğ¥Ğ¼Ğ¼...")).strip()
        reaction = reaction[:130] if len(reaction) > 130 else reaction
        
        return {"reaction": reaction, "mood_change": mood, "is_positive": is_pos}
        
    except Exception as e:
        logger.debug(f"[Groq] Parse error â†’ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ AI")
        return _local_ai_reaction(text, prompt_type)


# â”€â”€ ğŸ¯ MAIN Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ (ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒÑÑ‚ÑÑ Ğ² bot.py) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def get_news_with_reaction(count: int = 1, source: str = "forbes") -> List[dict]:
    """
    ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‡ĞµÑ€ĞµĞ· AI.
    
    Args:
        count: ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ĞµĞ¹ (1-10)
        source: "forbes", "stopgame", "ria_finance", "ria_politics" Ğ¸Ğ»Ğ¸ "mix"
    
    Returns:
        Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº: [{"title", "url", "summary", "source", "reaction", "mood_change", "is_positive"}, ...]
    """
    count = max(1, min(count, 10))
    
    fetchers = {
        "forbes": fetch_forbes,
        "stopgame": fetch_stopgame,
        "ria_finance": fetch_ria_finance,
        "ria_politics": fetch_ria_politics,
    }
    
    if source == "mix":
        news = []
        del fetchers["stopgame"]  # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ StopGame Ğ¸Ğ· Ğ¼Ğ¸ĞºÑĞ°, Ñ‚Ğ°Ğº ĞºĞ°Ğº Ñ‚Ğ°Ğ¼ Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸ Ğ½Ğµ Ğ¿Ğ¾ Ñ‚ĞµĞ¼Ğµ
        for name, fetcher in fetchers.items():
            try:
                items = await fetcher(max(1, count // 4))
                news.extend(items)
            except Exception as e:
                logger.debug(f"[{name}] Error: {e}")
        news = news[:count]
    else:
        fetcher = fetchers.get(source, fetch_forbes)
        news = await fetcher(count)
    
    if not news:
        logger.debug(f"[{source}] ĞĞµÑ‚ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ĞµĞ¹")
        return []
    
    # ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ‡ĞµÑ€ĞµĞ· AI
    results = []
    for n in news:
        try:
            context = f"Ğ—Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº: {n['title']}"
            ai = await analyze_with_groq(context, prompt_type="news")
            results.append({**n, **ai})
        except Exception as e:
            logger.debug(f"[AI] Error: {e}")
            ai = _local_ai_reaction(n["title"], prompt_type="news")
            results.append({**n, **ai})
    
    return results


async def get_weather_reaction() -> dict:
    """
    ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ñƒ Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‡ĞµÑ€ĞµĞ· AI.
    
    Returns:
        dict: {"temp", "feels_like", "humidity", "wind", "weather_code",
               "is_sunny", "is_rain", "reaction", "mood_change", "is_positive"}
    """
    weather = await fetch_weather()
    context = (
        f"Ğ¢ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ°: {weather['temp']}Â°C, "
        f"ĞŸĞ¾Ğ³Ğ¾Ğ´Ğ°: {'ÑĞ¾Ğ»Ğ½ĞµÑ‡Ğ½Ğ¾' if weather['is_sunny'] else 'Ğ´Ğ¾Ğ¶Ğ´ÑŒ' if weather['is_rain'] else 'Ğ¾Ğ±Ğ»Ğ°Ñ‡Ğ½Ğ¾'}"
    )
    ai = await analyze_with_groq(context, prompt_type="weather")
    return {**weather, **ai}


# â”€â”€ Ğ£Ñ‚Ğ¸Ğ»Ğ¸Ñ‚Ğ°: Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ° Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def clear_news_history():
    """ĞÑ‡Ğ¸Ñ‰Ğ°ĞµÑ‚ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¿Ñ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ĞµĞ¹"""
    global _seen_news
    _seen_news.clear()
    logger.debug("[CLEANUP] Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½Ğ°")